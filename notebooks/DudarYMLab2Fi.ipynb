{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qq_p8C9jzCO",
        "outputId": "b4ab2a61-cd48-4805-f9a5-c89f009ad261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Данные успешно загружены.\n"
          ]
        }
      ],
      "source": [
        "# @title Ячейка 1: Импорты и загрузка данных\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "try:\n",
        "    df_class = pd.read_csv('Loan_Default.csv')\n",
        "    df_reg = pd.read_csv('Car_Sales.csv')\n",
        "    print(\"Данные успешно загружены.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка загрузки: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой ячейке я готовлю грязный бейзлайн для линейных моделей.\n",
        "1.  **Сэмплирование:** Ограничиваю выборку 20%, чтобы ускорить вычисления.\n",
        "2.  **Кодирование:** Намеренно использую`LabelEncoder превращаю категории в числа $0, 1, 2...$. Для линейных моделей ($y = w \\cdot x + b$) это некорректный подход, так как он вводит ложный порядок например, $Region\\_2 > Region\\_1$, но это позволит нам позже оценить прирост качества от правильного One-Hot Encoding.\n",
        "3.  **Масштабирование:** Применяю StandardScaler, так как линейные модели зависят от величины весов, и разномасштабные признаки могут помешать сходимости."
      ],
      "metadata": {
        "id": "qvgJ-qynxpgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ячейка 2: Препроцессинг для Бейзлайна (Label Encoding)\n",
        "#  1. Классификация (Loan Default)\n",
        "# Берем семпл, чтобы было честно по сравнению с будущей имплементацией\n",
        "df_class_sample = df_class.sample(frac=0.2, random_state=42).copy()\n",
        "df_class_sample = df_class_sample.drop(columns=['ID', 'year'], errors='ignore')\n",
        "\n",
        "X_cls = df_class_sample.drop(columns=['Status'])\n",
        "y_cls = df_class_sample['Status']\n",
        "\n",
        "# Заполнение пропусков и Label Encoding\n",
        "num_cols_cls = X_cls.select_dtypes(include=['number']).columns\n",
        "cat_cols_cls = X_cls.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Импутация\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "X_cls[num_cols_cls] = imputer_num.fit_transform(X_cls[num_cols_cls])\n",
        "X_cls[cat_cols_cls] = SimpleImputer(strategy='most_frequent').fit_transform(X_cls[cat_cols_cls])\n",
        "\n",
        "# Label Encoding\n",
        "le = LabelEncoder()\n",
        "for col in cat_cols_cls:\n",
        "    X_cls[col] = le.fit_transform(X_cls[col].astype(str))\n",
        "\n",
        "# Масштабирование (Для линейных моделей это важно, но в sklearn есть встроенные солверы.\n",
        "# Однако для чистоты эксперимента сделаем StandardScaler)\n",
        "scaler_cls = StandardScaler()\n",
        "X_cls_scaled = scaler_cls.fit_transform(X_cls)\n",
        "\n",
        "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
        "    X_cls_scaled, y_cls, test_size=0.25, random_state=42, stratify=y_cls\n",
        ")\n",
        "\n",
        "# === 2. Регрессия (Car Sales) ===\n",
        "df_reg_clean = df_reg.dropna(subset=['Price']).copy()\n",
        "X_reg = df_reg_clean.drop(columns=['Price', 'Model'])\n",
        "y_reg = df_reg_clean['Price']\n",
        "\n",
        "# Импутация и кодирование\n",
        "num_cols_reg = X_reg.select_dtypes(include=['number']).columns\n",
        "cat_cols_reg = X_reg.select_dtypes(include=['object']).columns\n",
        "\n",
        "X_reg[num_cols_reg] = SimpleImputer(strategy='median').fit_transform(X_reg[num_cols_reg])\n",
        "X_reg[cat_cols_reg] = SimpleImputer(strategy='most_frequent').fit_transform(X_reg[cat_cols_reg])\n",
        "\n",
        "for col in cat_cols_reg:\n",
        "    X_reg[col] = le.fit_transform(X_reg[col].astype(str))\n",
        "\n",
        "# Масштабирование\n",
        "scaler_reg = StandardScaler()\n",
        "X_reg_scaled = scaler_reg.fit_transform(X_reg)\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg_scaled, y_reg, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Данные для бейзлайна подготовлены.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGkwOW8rj5xG",
        "outputId": "c65dc657-e477-4767-d67d-94a76f80637c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Данные для бейзлайна подготовлены.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ячейка 3: Обучение Бейзлайна (Sklearn)\n",
        "# 1. Логистическая регрессия (Классификация)\n",
        "# max_iter увеличено, чтобы градиентный спуск внутри sklearn успел сойтись\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "y_pred_cls = log_reg.predict(X_test_cls)\n",
        "y_pred_proba_cls = log_reg.predict_proba(X_test_cls)[:, 1]\n",
        "\n",
        "print(\"=== Результаты Бейзлайна (Логистическая регрессия) ===\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test_cls, y_pred_cls):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test_cls, y_pred_proba_cls):.4f}\")\n",
        "print(f\"F1-score:  {f1_score(y_test_cls, y_pred_cls):.4f}\")\n",
        "\n",
        "\n",
        "# 2. Линейная регрессия\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "y_pred_reg = lin_reg.predict(X_test_reg)\n",
        "\n",
        "print(\"\\n=== Результаты Бейзлайна (Линейная регрессия) ===\")\n",
        "r2_base = r2_score(y_test_reg, y_pred_reg)\n",
        "mae_base = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "print(f\"R2:  {r2_base:.4f}\")\n",
        "print(f\"MAE: {mae_base:.2f}\")\n",
        "\n",
        "# Визуализация весов\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(range(len(lin_reg.coef_)), lin_reg.coef_)\n",
        "plt.title(\"Веса признаков линейной регрессии (Бейзлайн)\")\n",
        "plt.xlabel(\"Индекс признака\")\n",
        "plt.ylabel(\"Вес\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "RgKlPB_WkEoP",
        "outputId": "25e21449-8ab1-4473-f0a9-b83ac7a55ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Результаты Бейзлайна (Логистическая регрессия) ===\n",
            "Accuracy:  0.7824\n",
            "ROC-AUC:   0.7494\n",
            "F1-score:  0.3433\n",
            "\n",
            "=== Результаты Бейзлайна (Линейная регрессия) ===\n",
            "R2:  0.2506\n",
            "MAE: 11509.62\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Анализ Бейзлайна:**\n",
        "1.  **Регрессия ($R^2 \\approx 0.25$):** Это плохо. Линейная регрессия пытается провести прямую линию через облако точек, но выбросы (машины за 300к) и неправильное кодирование (LabelEncoding) не дают ей этого сделать. KNN справился лучше ($0.61$), потому что он локален, а л регрессия глобальна.\n",
        "2.  **Классификация (ROC-AUC $\\approx 0.75$):** Тоже хуже, чем KNN ($0.91$). Низкий F1-score ($0.34$) говорит о том, что модель плохо находит позитивный класс дефолт. Навернрое, зависимость между признаками и дефолтом нелинейная, либо шум от LabelEncoding сбивает веса."
      ],
      "metadata": {
        "id": "UfNPpOGIkuwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Улучшение бейзлайна\n",
        "\n",
        "### a. Формулирование гипотез\n",
        "Низкое качество бейзлайна (особенно в регрессии, $R^2=0.25$) обусловлено нарушением предположений линейных моделей.\n",
        "\n",
        "1.  **Гипотеза OHE:** Использование Label Encoding для номинальных переменных (Brand, Type) вводит ложный порядковый смысл. One-Hot Encoding создаст бинарные признаки, что позволит модели выучить индивидуальный вес для каждой категории.\n",
        "2.  **Гипотеза Log-Target:** Целевая переменная Price имеет логнормальное распределение. Обучение на log(Price) линеаризует зависимость и уменьшит влияние выбросов.\n",
        "3.  **Гипотеза Регуляризации:** После OHE количество признаков вырастет. Использование Ridge (L2) или Lasso (L1) регрессии предотвратит переобучение и веса не будут взрываться."
      ],
      "metadata": {
        "id": "oWmEc3ZRk2Z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализую улучшенную предобработку данных на основе выдвинутых гипотез.\n",
        "\n",
        "Для регрессии:\n",
        "1.  Удаляю выбросы и логарифмирую целевую переменную: $y_{new} = \\ln(1 + y)$. Это приближает распределение таргета к нормальному, линейная регрессия предполагает гауссово распределение остатков $\\epsilon \\sim N(0, \\sigma^2)$.\n",
        "2.  Перехожу на One-Hot Encoding. В отличие от Label Encoding, это позволяет модели выучить отдельный вес $w_i$ для каждой категории, не вводя ложного порядка ($2 > 1$).\n",
        "\n",
        "Для классификации также применяю OHE и нормализую данные через StandardScaler ($z = \\frac{x - \\mu}{\\sigma}$)."
      ],
      "metadata": {
        "id": "CPf1gurYyS1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ячейка 4: Подготовка улучшенных данных (OHE + Log)\n",
        "\n",
        "# 1. Регрессия (Улучшенная)\n",
        "# Удаляем выбросы (как в Лаб 1)\n",
        "q99 = df_reg_clean['Price'].quantile(0.99)\n",
        "df_reg_imp = df_reg_clean[df_reg_clean['Price'] < q99].copy()\n",
        "\n",
        "# Логарифмируем таргет\n",
        "df_reg_imp['log_Price'] = np.log1p(df_reg_imp['Price'])\n",
        "\n",
        "# оставляем Brand, Body..\n",
        "X_reg_imp = df_reg_imp.drop(columns=['Price', 'log_Price', 'Model'])\n",
        "y_reg_imp = df_reg_imp['log_Price']\n",
        "\n",
        "# OHE + Scaling\n",
        "X_reg_imp = pd.get_dummies(X_reg_imp, drop_first=True)\n",
        "\n",
        "# Заполняем пропуски если появились после dummies, хотя get_dummies их обычно игнорирует, но на всякий сл\n",
        "imputer_reg = SimpleImputer(strategy='median')\n",
        "X_reg_imp = pd.DataFrame(imputer_reg.fit_transform(X_reg_imp), columns=X_reg_imp.columns)\n",
        "\n",
        "scaler_reg_imp = StandardScaler()\n",
        "X_reg_imp_scaled = scaler_reg_imp.fit_transform(X_reg_imp)\n",
        "\n",
        "X_train_reg_imp, X_test_reg_imp, y_train_reg_imp, y_test_reg_imp = train_test_split(\n",
        "    X_reg_imp_scaled, y_reg_imp, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# 2. Классификация (Улучшенная)\n",
        "# Удаляем признаки, которые я решил убрать\n",
        "X_cls_imp = df_class_sample.drop(columns=['Status', 'total_units', 'loan_purpose'], errors='ignore')\n",
        "y_cls_imp = df_class_sample['Status']\n",
        "\n",
        "num_cols_imp = X_cls_imp.select_dtypes(include=['number']).columns\n",
        "cat_cols_imp = X_cls_imp.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Обработка пропусков\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "X_cls_imp[num_cols_imp] = imputer_num.fit_transform(X_cls_imp[num_cols_imp])\n",
        "\n",
        "# Для категорий\n",
        "X_cls_imp[cat_cols_imp] = SimpleImputer(strategy='most_frequent').fit_transform(X_cls_imp[cat_cols_imp])\n",
        "\n",
        "# OHE\n",
        "X_cls_imp = pd.get_dummies(X_cls_imp, columns=cat_cols_imp, drop_first=True)\n",
        "\n",
        "# Scaling\n",
        "scaler_cls_imp = StandardScaler()\n",
        "X_cls_imp_scaled = scaler_cls_imp.fit_transform(X_cls_imp)\n",
        "\n",
        "X_train_cls_imp, X_test_cls_imp, y_train_cls_imp, y_test_cls_imp = train_test_split(\n",
        "    X_cls_imp_scaled, y_cls_imp, test_size=0.25, random_state=42, stratify=y_cls_imp\n",
        ")\n",
        "\n",
        "print(\"Улучшенные данные подготовлены (OHE + Log + Scale).\")\n",
        "print(f\"Признаков в регрессии: {X_train_reg_imp.shape[1]}\")\n",
        "print(f\"Признаков в классификации: {X_train_cls_imp.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVFAVvCwkwCB",
        "outputId": "70fbc2e4-55d0-4b58-ec84-35cba7c434a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Улучшенные данные подготовлены (OHE + Log + Scale).\n",
            "Признаков в регрессии: 18\n",
            "Признаков в классификации: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Провожу подбор гиперпараметров и обучение финальных моделей на улучшенных данных.\n",
        "\n",
        "1.  **Регрессия (Ridge):** Использую L2-регуляризацию (функция потерь $L = MSE + \\alpha \\sum w_i^2$), чтобы справиться с мультиколлинеарностью, возникшей после One-Hot Encoding. После предсказания выполняю обратное преобразование таргета $\\hat{y} = e^{\\hat{y}_{log}} - 1$, чтобы оценить качество в реальных ценах.\n",
        "2.  **Классификация:** Настраиваю параметр регуляризации $C$ для Логистической регрессии.\n",
        "3.  **Интерпретация:** Анализирую веса модели ($w$). Это главное преимущество линейных моделей - мы видим, какие именно признаки вносят наибольший вклад в вероятность дефолта."
      ],
      "metadata": {
        "id": "QokQjT8Pyk5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ячейка 5: GridSearch с Регуляризацией и Оценка\n",
        "# 1. Регрессия (Ridge Regression - L2)\n",
        "# Ridge лучше работает, когда признаки коррелируют (а после OHE это так)\n",
        "params_ridge = {'alpha': [0.1, 1, 10, 100]}\n",
        "grid_reg = GridSearchCV(Ridge(), params_ridge, cv=5, scoring='r2')\n",
        "grid_reg.fit(X_train_reg_imp, y_train_reg_imp)\n",
        "\n",
        "best_model_reg = grid_reg.best_estimator_\n",
        "print(f\"Best Ridge Alpha: {grid_reg.best_params_}\")\n",
        "\n",
        "# Предсказание\n",
        "y_pred_log_imp = best_model_reg.predict(X_test_reg_imp)\n",
        "y_pred_reg_imp = np.expm1(y_pred_log_imp)\n",
        "y_test_reg_orig = np.expm1(y_test_reg_imp)\n",
        "\n",
        "r2_imp = r2_score(y_test_reg_orig, y_pred_reg_imp)\n",
        "print(f\"Improved R2: {r2_imp:.4f} (Было: {r2_base:.4f})\")\n",
        "\n",
        "\n",
        "# 2. Классификация (Logistic Regression + L2)\n",
        "params_log = {'C': [0.01, 0.1, 1, 10]}\n",
        "grid_cls = GridSearchCV(LogisticRegression(max_iter=1000), params_log, cv=3, scoring='roc_auc')\n",
        "grid_cls.fit(X_train_cls_imp, y_train_cls_imp)\n",
        "\n",
        "best_model_cls = grid_cls.best_estimator_\n",
        "print(f\"\\nBest Logistic C: {grid_cls.best_params_}\")\n",
        "\n",
        "y_pred_cls_imp = best_model_cls.predict(X_test_cls_imp)\n",
        "y_pred_proba_cls_imp = best_model_cls.predict_proba(X_test_cls_imp)[:, 1]\n",
        "\n",
        "roc_imp = roc_auc_score(y_test_cls_imp, y_pred_proba_cls_imp)\n",
        "f1_imp = f1_score(y_test_cls_imp, y_pred_cls_imp)\n",
        "\n",
        "print(f\"Improved ROC-AUC: {roc_imp:.4f} (Было: 0.7494)\")\n",
        "print(f\"Improved F1:      {f1_imp:.4f} (Было: 0.3433)\")\n",
        "\n",
        "# Вывод коэффициентов для топ признаков (Интерпретируемость!)\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_cls_imp.columns,\n",
        "    'Weight': best_model_cls.coef_[0]\n",
        "})\n",
        "print(\"\\nТоп-5 признаков, влияющих на дефолт (+ повышают риск, - понижают):\")\n",
        "print(coefficients.reindex(coefficients.Weight.abs().sort_values(ascending=False).index).head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnTH43bzlRfH",
        "outputId": "c51cad83-554f-4558-9c09-979b4ac0d2f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Ridge Alpha: {'alpha': 1}\n",
            "Improved R2: 0.6871 (Было: 0.2506)\n",
            "\n",
            "Best Logistic C: {'C': 10}\n",
            "Improved ROC-AUC: 0.8564 (Было: 0.7494)\n",
            "Improved F1:      0.6576 (Было: 0.3433)\n",
            "\n",
            "Топ-5 признаков, влияющих на дефолт (+ повышают риск, - понижают):\n",
            "                              Feature    Weight\n",
            "28                   credit_type_EQUI  4.227156\n",
            "37  submission_of_application_to_inst  0.619506\n",
            "2                Interest_rate_spread -0.510510\n",
            "8                                 LTV  0.489195\n",
            "6                              income -0.446004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Гипотезы подтвердились полностью:\n",
        "1.  **Регрессия:** $R^2$ вырос с 0.25 до 0.69. логарифмирование таргета и удаление выбросов дали линейной модели увидеть зависимость.\n",
        "2.  **Классификация:** F1-score вырос в два раза (0.34 $\\to$ 0.66). Модель наконец-то научилась находить дефолтных заемщиков, а не только отказников. И мы увидели топ-признак credit_type_EQUI кредит под залог имеющейся недвижимости — это мощный инсайт для бизнеса"
      ],
      "metadata": {
        "id": "ltwDEevtl0nR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Имплементация алгоритмов (Пункт 4)\n",
        "\n",
        "Теперь мы напишем свой класс линейной модели.\n",
        "Как Senior Python Developer, я реализую универсальный класс `MyLinearModel`, который будет поддерживать и регрессию (Linear Regression), и классификацию (Logistic Regression) через переключатель `task`.\n",
        "\n",
        "**Математика под капотом (Градиентный спуск):**\n",
        "1.  **Линейная комбинация:** $z = w_0 + w_1 x_1 + \\dots + w_n x_n = X \\cdot w$\n",
        "2.  **Функция активации:**\n",
        "    *   Регрессия: $f(z) = z$ (линейная)\n",
        "    *   Классификация: $f(z) = \\sigma(z) = \\frac{1}{1 + e^{-z}}$ (сигмоида)\n",
        "3.  **Градиент (векторное вычисление):**\n",
        "    $$ \\nabla w = \\frac{1}{m} X^T (\\hat{y} - y) + \\alpha \\cdot w $$\n",
        "    Где $\\alpha$ — коэффициент L2-регуляризации (мы добавим её сразу, чтобы соответствовать пункту 4f)."
      ],
      "metadata": {
        "id": "4IiHbqkbmBSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ячейка 6: Класс MyLinearModel\n",
        "class MyLinearModel:\n",
        "    def __init__(self, task='regression', lr=0.01, n_iter=1000, alpha=0.0):\n",
        "        \"\"\"\n",
        "        task: 'regression' или 'classification'\n",
        "        lr: learning rate (шаг обучения)\n",
        "        n_iter: количество итераций градиентного спуска\n",
        "        alpha: коэффициент L2 регуляризации\n",
        "        \"\"\"\n",
        "        self.task = task\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "        self.alpha = alpha\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.loss_history = []\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        z = np.clip(z, -250, 250)\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Инициализация весов нулями\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Градиентный спуск\n",
        "        for _ in range(self.n_iter):\n",
        "            # 1. Линейная комбинация\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "            # 2. Предсказание (активация)\n",
        "            if self.task == 'classification':\n",
        "                y_pred = self._sigmoid(linear_model)\n",
        "            else:\n",
        "                y_pred = linear_model\n",
        "\n",
        "            # 3. Вычисление градиентов\n",
        "            # Производная потерь по весам: (1/m) * X.T * (y_pred - y) + регуляризация\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y)) + (self.alpha * self.weights)\n",
        "            # Производная потерь по bias: (1/m) * sum(y_pred - y)\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            # 4. Обновление параметров\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "        if self.task == 'classification':\n",
        "            y_pred_proba = self._sigmoid(linear_model)\n",
        "            return [1 if i > 0.5 else 0 for i in y_pred_proba]\n",
        "        else:\n",
        "            return linear_model\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # Только для классификации\n",
        "        if self.task != 'classification':\n",
        "            raise ValueError(\"predict_proba is only for classification\")\n",
        "        X = np.array(X)\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        return self._sigmoid(linear_model)\n",
        "\n",
        "print(\"Класс MyLinearModel (с поддержкой L2 и SGD) создан.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz-FVXQ7l1XT",
        "outputId": "ec87762b-0b0b-43ea-d9e2-f1a0d700822b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Класс MyLinearModel (с поддержкой L2 и SGD) создан.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ячейка 7: Класс MyLinearModel\n",
        "# === ЭТАП 4: Имплементация и Сравнение (Полный цикл) ===\n",
        "\n",
        "#  Пункты 4b, 4c, 4d (Бейзлайн данные)\n",
        "# Обучаем MyLinearModel на X_train_reg / X_train_cls (с LabelEncoding)\n",
        "# ---------------------------------------------------------\n",
        "print(\"=== 4b-4d. Тест MyLinearModel на БАЗОВЫХ данных (сравнение с п.2) ===\\n\")\n",
        "\n",
        "# -- Регрессия (Base) --\n",
        "# Используем те же данные, что и в ячейке 2\n",
        "my_reg_base = MyLinearModel(task='regression', lr=0.01, n_iter=5000, alpha=0.001)\n",
        "my_reg_base.fit(X_train_reg, y_train_reg)\n",
        "y_pred_base_my = my_reg_base.predict(X_test_reg)\n",
        "\n",
        "r2_my_base = r2_score(y_test_reg, y_pred_base_my)\n",
        "print(f\"[Регрессия Base] MyModel R2: {r2_my_base:.4f}\")\n",
        "print(f\"                 Sklearn R2: {r2_base:.4f}\")\n",
        "\n",
        "# -- Классификация (Base) --\n",
        "my_cls_base = MyLinearModel(task='classification', lr=0.1, n_iter=5000, alpha=0.001)\n",
        "my_cls_base.fit(X_train_cls, y_train_cls)\n",
        "y_pred_proba_base_my = my_cls_base.predict_proba(X_test_cls)\n",
        "\n",
        "roc_my_base = roc_auc_score(y_test_cls, y_pred_proba_base_my)\n",
        "print(f\"[Классификация Base] MyModel ROC-AUC: {roc_my_base:.4f}\")\n",
        "print(f\"                     Sklearn ROC-AUC: {0.7494:.4f}\") # Значение из п.2\n",
        "\n",
        "\n",
        "# ЧАСТЬ 2: Пункты 4f, 4g, 4h, 4i (Улучшенные данные)\n",
        "# Добавляем техники из п.3 (OHE, Log-target, Tuning)\n",
        "print(\"-\" * 60)\n",
        "print(\"=== 4f-4i. Тест MyLinearModel на улучщена данных (сравнение с п.3) ===\\n\")\n",
        "\n",
        "# -- Регрессия (Improved) --\n",
        "# Используем подобранные параметры для сходимости (lr=0.001, n_iter=50000)\n",
        "my_reg_imp = MyLinearModel(task='regression', lr=0.001, n_iter=50000, alpha=0.001)\n",
        "my_reg_imp.fit(X_train_reg_imp, y_train_reg_imp)\n",
        "\n",
        "y_pred_log_my = my_reg_imp.predict(X_test_reg_imp)\n",
        "y_pred_reg_my = np.expm1(y_pred_log_my) # Обратный лог\n",
        "\n",
        "r2_my_imp = r2_score(y_test_reg_orig, y_pred_reg_my)\n",
        "print(f\"[Регрессия Imp] MyModel R2: {r2_my_imp:.4f}\")\n",
        "print(f\"                Sklearn R2: {r2_imp:.4f}\")\n",
        "\n",
        "# -- Классификация (Improved) --\n",
        "# Добавляем регуляризацию alpha=0.1 (аналог C=10)\n",
        "my_cls_imp = MyLinearModel(task='classification', lr=0.1, n_iter=5000, alpha=0.001)\n",
        "my_cls_imp.fit(X_train_cls_imp, y_train_cls_imp)\n",
        "y_pred_proba_imp_my = my_cls_imp.predict_proba(X_test_cls_imp)\n",
        "\n",
        "roc_my_imp = roc_auc_score(y_test_cls_imp, y_pred_proba_imp_my)\n",
        "print(f\"[Классификация Imp] MyModel ROC-AUC: {roc_my_imp:.4f}\")\n",
        "print(f\"                    Sklearn ROC-AUC: {roc_imp:.4f}\")\n",
        "print(\"                    Вывод: Качество улучшилось относительно п.4b.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cwS09g1mAVG",
        "outputId": "1b42d584-2b02-4983-f5fb-e16f2f95f52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 4b-4d. Тест MyLinearModel на БАЗОВЫХ данных (сравнение с п.2) ===\n",
            "\n",
            "[Регрессия Base] MyModel R2: 0.2507\n",
            "                 Sklearn R2: 0.2506\n",
            "[Классификация Base] MyModel ROC-AUC: 0.7493\n",
            "                     Sklearn ROC-AUC: 0.7494\n",
            "------------------------------------------------------------\n",
            "=== 4f-4i. Тест MyLinearModel на улучщена данных (сравнение с п.3) ===\n",
            "\n",
            "[Регрессия Imp] MyModel R2: 0.6869\n",
            "                Sklearn R2: 0.6871\n",
            "[Классификация Imp] MyModel ROC-AUC: 0.8556\n",
            "                    Sklearn ROC-AUC: 0.8564\n",
            "                    Вывод: Качество улучшилось относительно п.4b.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Итоговые выводы по Лабораторной работе №2\n",
        "\n",
        "## 1. Линейные модели и Препроцессинг\n",
        "*   **Ключевая роль подготовки данных:** Исследование показало, что для линейных моделей Feature Engineering важнее выбора алгоритма. На сырых данных модель была непригодна ($R^2 \\approx 0.25$), но после применения **One-Hot Encoding**, **логарифмирования таргета** и очистки выбросов качество выросло до $R^2 \\approx 0.69$.\n",
        "*   **Интерпретируемость:** В отличие от KNN, линейные модели позволили выделить ключевые признаки. Например, в задаче кредитного скоринга наличие залога недвижимости credit_type_EQUI оказалось сильнейшим предиктором дефолта.\n",
        "\n",
        "## 2. Сравнение алгоритмов Lab 1 против Lab 2\n",
        "*   **Регрессия:** Даже улучшенная линейная регрессия ($R^2=0.69$) уступила результатам KNN из первой лабораторной работы ($R^2=0.83$). цены автомобиля от параметров год, пробег имеет сложную нелинейную структуру, которую прямая линия не может описать идеально.\n",
        "*   **Классификация:** Логистическая регрессия показала достойный результат (ROC-AUC $\\approx 0.85$), лишь немного уступив KNN ($0.91$), но выиграв в скорости работы и прозрачности решений.\n",
        "\n",
        "## 3. Результаты имплементации\n",
        "В ходе работы был самостоятельно реализован алгоритм обучения линейных моделей через **Градиентный спуск (SGD)**.\n",
        "*   Результаты собственной реализации MyLinearModel практически полностью совпали с эталонной реализацией из библиотеки sklearn как в задаче классификации, так и в регрессии (расхождение метрик менее 0.01).\n",
        "\n",
        "## 4. Общее заключение\n",
        "Я успешно построил пайплайн обучения линейных моделей. Линейная регрессия и Логистическая регрессия - мощные бейзлайны, которые требуют тщательной настройки данных, но дают высокую интерпретируемость и контроль над процессом обучения."
      ],
      "metadata": {
        "id": "39wDf_kTngdH"
      }
    }
  ]
}