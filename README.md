# –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –ú–∞—à–∏–Ω–Ω–æ–≥–æ –û–±—É—á–µ–Ω–∏—è

| –°—Ç—É–¥–µ–Ω—Ç                | –ì—Ä—É–ø–ø–∞      | –û—Ü–µ–Ω–∫–∞ |
| ---------------------- | ----------- | ------ |
| –î—É–¥–∞—Ä—å –Æ—Ä–∏–π –ú–æ—Ö—Å–µ–Ω–æ–≤–∏—á | –ú8–û-409–ë-22 |        |

–í –¥–∞–Ω–Ω–æ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã 5 –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö —Ä–∞–±–æ—Ç –ø–æ –∫—É—Ä—Å—É "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ". 
–í —Ä–∞–º–∫–∞—Ö –∫—É—Ä—Å–∞ –±—ã–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã ML, –ø—Ä–æ–≤–µ–¥–µ–Ω –∏—Ö —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–∞–∂–¥–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –Ω–∞ —á–∏—Å—Ç–æ–º Python/NumPy.

## üìÇ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

| –õ–∞–±. | –¢–µ–º–∞ | –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ |
| :--- | :--- | :--- |
| **‚Ññ1** | **K-Nearest Neighbors** | `KNN`, `StandardScaler`, `Manhattan Distance` |
| **‚Ññ2** | **–õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏** | `Linear Regression`, `Logistic Regression`, `SGD`, `L2 Regularization`, `One-Hot Encoding` |
| **‚Ññ3** | **–†–µ—à–∞—é—â–∏–µ –¥–µ—Ä–µ–≤—å—è** | `Decision Tree`, `Pruning`, `Gini Impurity`, `Overfitting` |
| **‚Ññ4** | **–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å** | `Random Forest`, `Bagging`, `Bootstrap`, `Ensemble` |
| **‚Ññ5** | **–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥** | `Gradient Boosting`, `Residuals`, `Log-Loss` |

## üìä –î–∞–Ω–Ω—ã–µ

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –¥–≤–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Kaggle:
1.  **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:** [Loan Default Dataset](https://www.kaggle.com/datasets/yasserh/loan-default-dataset) ‚Äî –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–∞ –ø–æ –∫—Ä–µ–¥–∏—Ç—É.
2.  **–†–µ–≥—Ä–µ—Å—Å–∏—è:** [Car Sales Dataset](https://www.kaggle.com/datasets/smritisingh1997/car-salescsv) ‚Äî –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è.

## üèÜ –°–≤–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–†–µ–≥—Ä–µ—Å—Å–∏—è)

–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π (–º–µ—Ç—Ä–∏–∫–∞ $R^2$) –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ –ø–æ—Å–ª–µ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:

| –ê–ª–≥–æ—Ä–∏—Ç–º | $R^2$ Score | –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (ROC-AUC/Acc) | –í—ã–≤–æ–¥ |
| :--- | :---: | :--- | :--- |
| **Linear Regression** | 0.69 | ~0.85 | –ü–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–æ —Å–ª–æ–∂–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏. |
| **KNN** | 0.83 | ~0.92 | –°–∏–ª—å–Ω—ã–π –±–µ–π–∑–ª–∞–π–Ω, –Ω–æ –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–π –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –ö—Ä–∏—Ç–∏—á–µ–Ω –∫ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é. |
| **Decision Tree** | 0.85 | ~0.99 | –°–∫–ª–æ–Ω–Ω–æ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é. –ò–¥–µ–∞–ª—å–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö. | 
| **Random Forest** | **0.91** | **~0.972** | –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –∫–æ—Ä–æ–±–∫–∏. –°—Ç–∞–±–∏–ª–µ–Ω, –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è, –≥–∞—Å–∏—Ç –¥–∏—Å–ø–µ—Ä—Å–∏—é. |
| **Gradient Boosting** | **0.91** | **~0.971** | –í—ã—Å–æ—á–∞–π—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å. –¢—Ä–µ–±—É–µ—Ç —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ learning rate –∏ —á–∏—Å–ª–∞ –¥–µ—Ä–µ–≤—å–µ–≤. |

## üõ†Ô∏è –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –±—ã–ª–∞ –Ω–∞–ø–∏—Å–∞–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (–∫–ª–∞—Å—Å—ã `MyKNN`, `MyLinearModel`, `MyDecisionTree`, `MyRandomForest`, `MyGradientBoosting`), –∫–æ—Ç–æ—Ä–∞—è —Å—Ä–∞–≤–Ω–∏–≤–∞–ª–∞—Å—å —Å —ç—Ç–∞–ª–æ–Ω–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏–∑ `scikit-learn`.

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ–∫–∞–∑–∞–ª–∏ –º–µ—Ç—Ä–∏–∫–∏, –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –∏–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–ª–∏–∑–∫–∏–µ –∫ –±–∏–±–ª–∏–æ—Ç–µ—á–Ω—ã–º, —á—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–Ω–æ–≤ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤.

## üöÄ –ó–∞–ø—É—Å–∫
1. –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π.
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: `pip install -r requirements.txt`
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–æ—É—Ç–±—É–∫–∏ –≤ Jupyter Lab –∏–ª–∏ Google Colab.
